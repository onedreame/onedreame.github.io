---
layout:     post
title:      pytorch调参
subtitle:   调参技巧记录
date:       2020-06-05
author:     OD
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Pytorch
    - finetune
---

# pytorch调参

## 1. 生活中的chatbot

​	目前在深度学习领域分类两个派别，一派为学院派，研究强大、复杂的模型网络和实验方法，为了追求更高的性能；另一派为工程派，旨在将算法更稳定、高效的落地在硬件平台上，效率是其追求的目标。复杂的模型固然具有更好的性能，但是高额的存储空间、计算资源消耗是使其难以有效的应用在各硬件平台上的重要原因。

​	在调试chatbot的过程中踩过的坑：

1. 学习率问题。非常重要，设得太大，模型会发散，直接崩了；过小，则一直震荡，无法跳出局部最优解。
2. 在我们实现自己的模型的时候，有很多时候写完了，训练完了发现结果不尽如人意，这时候的原因可能是多方面的，比如超参数，比如模型的结构等等，无论哪一种，都是对于我们时间的浪费，这个时候，合理的做法是构造一个很小的数据集，测试在这个小数据集上模型的效果，小数据集很快就跑完了，所以对于我们调试超参数，调试模型结构都大有裨益。

​	
